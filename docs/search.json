[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GG606 Winter 2023",
    "section": "",
    "text": "1 Introduction\nScheduled as Tuesdays 09:00–11:20, DAWB 3-105 (Dr Alvin Woods Building)"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "GG606 Winter 2023",
    "section": "1.1 Course Description",
    "text": "1.1 Course Description\nThis course covers the data science skills comprising data visualization, data wrangling (cleaning, combining, modelling, etc.), and methodological and statistical design, which are an important part of the scientific method."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "GG606 Winter 2023",
    "section": "1.2 Learning Objectives",
    "text": "1.2 Learning Objectives\n\ndescribe the characteristics of datasets in order to plan for data wrangling and visualisation\ndevelop workflows for dealing with disparate data types\napply knowledge to tidy, transform, visualise, model datasets similar to thesis/project data\ndevelop a template for a reproducible workflow including metadata"
  },
  {
    "objectID": "index.html#goals-of-the-course",
    "href": "index.html#goals-of-the-course",
    "title": "GG606 Winter 2023",
    "section": "1.3 Goals of the Course",
    "text": "1.3 Goals of the Course\nSkills and products developed in this course will be employed on models built on example data sets generated for each research chapter of each student’s thesis/project, i.e. data sets that are messy, contain holes, and have different statistical distributions. Students will benefit from working with data flows they have developed and modified based on collaborative interactions with classmates via multi-user repositories."
  },
  {
    "objectID": "index.html#required-text",
    "href": "index.html#required-text",
    "title": "GG606 Winter 2023",
    "section": "1.4 Required Text",
    "text": "1.4 Required Text\n\nWickham H, Grolemund G. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media. Chicago, available online at http://r4ds.had.co.nz\nTimbers T-A, Campbell T, Lee M. 2021. Introduction to Data Science, available online at https://datasciencebook.ca"
  },
  {
    "objectID": "index.html#supplementary-readings",
    "href": "index.html#supplementary-readings",
    "title": "GG606 Winter 2023",
    "section": "1.5 Supplementary Readings",
    "text": "1.5 Supplementary Readings\n\nBroman KW, Woo KH. 2018. Data Organization in Spreadsheets. The American Statistician 72(1): 2-10. https://doi.org/10.1080/00031305.2017.1375989\nBryan J, et al. 2018. Happy Git and GitHub for the useR. http://happygitwithr.com/\nHampton SE, Anderson SS, Bagby SC, Gries C, Han X, Hart EM, Jones MB, Lenhardt WC, MacDonald A, Michener WK, Mudge J, Pourmokhtarian A, Schildhauer MP, Woo KH, Zimmerman N. 2015. The Tao of open science for ecology. Ecosphere 6(7):120. http://dx.doi.org/10.1890/ES14-00402.1\nHart EM, Barmby P, LeBauer D, Michonneau F, Mount S, Mulrooney P, et al. 2016. Ten Simple Rules for Digital Data Storage. PLoS Comput Biol12(10): e1005097. https://doi.org/10.1371/journal.pcbi.1005097\nSixteen peer-reviewed journal articles in the PeerJ Collection, Practical Data Science for Stats: https://peerj.com/collections/50-practicaldatascistats/\nWilke CO. 2019. Fundamental of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly Media. Chicago, https://clauswilke.com/dataviz/"
  },
  {
    "objectID": "index.html#cheatsheets",
    "href": "index.html#cheatsheets",
    "title": "GG606 Winter 2023",
    "section": "1.6 Cheatsheets",
    "text": "1.6 Cheatsheets\n\nPosit Cheatsheets"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "GG606 Winter 2023",
    "section": "1.7 Schedule",
    "text": "1.7 Schedule\n\nWrangling\n\n\nWeek\nTopic\nTools\n\n\n\n\nJanuary 10\nIntroduction, data visualisation\n\n\n\nJanuary 17\nData workflows\n\n\n\nJanuary 24\nData transformations and wrangling\n\n\n\nJanuary 31\nExploration, data types\n\n\n\nFebruary 7\nTidying data, data forms and formats\n\n\n\nFebruary 14\nDates, times, time series\n\n\n\nFebruary 21\nReading Week\n\n\n\nFebruary 28\nWork Period & Catch Up\n\n\n\n\n\nData Wrangling in Practice\n\n\nWeek\nTopic\nTools\n\n\n\n\nMarch 7\nPipes and functions\n\n\n\nMarch 14\nFunctions, more functions and packages\n\n\n\nMarch 21\nPresentations\n\n\n\nMarch 28\nPresentations"
  },
  {
    "objectID": "index.html#evaluation",
    "href": "index.html#evaluation",
    "title": "GG606 Winter 2023",
    "section": "1.8 Evaluation",
    "text": "1.8 Evaluation\n\n\n\n\n\n\n\n\nAssessment\nWeighting\nDue Date\n\n\n\n\nAssignments (2×15%)\n30%\nFebruary 7\nMarch 7\n\n\nAnalytics Demo\n40%\nMarch 21 & 28\n\n\nParticipation\n15%\n\n\n\nCourse notebook\n15%\n\n\n\nTotal\n100%\n\n\n\n\n\n1.8.1 Assignments\nTwo assignments will require students to demonstrate data wrangling and visualisation skills learned in the course. Data sets will be provided.\n\n\n1.8.2 Term Project\nStudents will demonstrate a technical topic with a complete analytic walk-through of an existing analysis from a paper in an area of interest or through a demonstration of a specialized statistical or analysis method through the use of R packages.\n\n\n1.8.3 Participation\nStudents will be expected to attend and participate in designated course times. Participate includes contributing to discussions and working collaboratively with other students when needed."
  },
  {
    "objectID": "assignments.html#assignment-1-importing-parsing-and-querying-data-in-the-wild",
    "href": "assignments.html#assignment-1-importing-parsing-and-querying-data-in-the-wild",
    "title": "2  Assignments",
    "section": "2.1 Assignment 1 Importing, parsing, and querying data in the wild",
    "text": "2.1 Assignment 1 Importing, parsing, and querying data in the wild\nThe National Earthquake Information Center (NEIC) determines the location and size of all significant earthquakes that occur worldwide and disseminates this information immediately to national and international agencies, scientists, critical facilities, and the general public. The NEIC compiles and provides to scientists and to the public an extensive seismic database that serves as a foundation for scientific research through the operation of modern digital national and global seismograph networks and cooperative international agreements. The NEIC is the national data center and archive for earthquake information.\nThis dataset includes a record of the date, time, location, depth, magnitude, and source of every earthquake with a reported magnitude 5.5 or higher since 1965.\nYou can use this Rmd file as a template. Rstudio (now posit) has some easy to follow lessons on RMarkdown https://rmarkdown.rstudio.com/lesson-1.html . We will briefly discuss Rmarkdown in class.\nYour assignment should answer the following questions and be as reproducible as you can make it (i.e., I should be able to reproduce your answers).This means that you must read data in from a URL so that I can replicate your work, do not include any external data files in your submission, only submit one .Rmd file. You can use external data to supplement your anlayses if you want to. For each answer provide a short write up explaining the approach you took to the question. There are not necessarily correct answers, and I expect your answers to vary from classmates, however you should be able to provide a clear illustration via your code of how you arrived at the conclusion you did.\nQuestions:\n\nRead the data in and clean it for analysis, using the readr package functions for reading and parsing data. [5 marks]\nDid more earthquakes happen on weekends or weekdays? Include a figure [5 marks]\nHas there been any change in the frequency of earthquakes? Include a figure [5 marks]\nWhere were there more earthquakes in the 1980s, South America or North America? Include a figure [5 marks]\nHas there been any geographic shifts in the distribution of earthquakes? [10 marks] Include a figure\nComment on how lessons from Wilke’s Fundamentals of Data Visualization were applied to each figure with specific reference to book sections [5 marks]"
  },
  {
    "objectID": "assignments.html#assignment-2-real-world-data-wrangling",
    "href": "assignments.html#assignment-2-real-world-data-wrangling",
    "title": "2  Assignments",
    "section": "2.2 Assignment 2 Real world data wrangling",
    "text": "2.2 Assignment 2 Real world data wrangling\nThe Canadian Census from 2021 will soon be released and made available to the public. You will analyze Canadian census data for this assignment. However, the real goal of this assignment is to get you familiar with the process of learning a new R package. More than anything - the R landscape of packages is quickly changing and being able to learn about, understand, and use new packages is a vital skill for scientific data wrangling. Often, new published papers will have related R packages and may or may not have clear documentation or vignettes (which are best for getting up and running). Evaluating an R package requires quickly ascertaining whether a package can do what you need it to, how to format data for it, what outputs are generated, and what parameters need to be set/configured. There is very little standardization across R packages (outside of the tidyverse) so this step of evaluation can take some time.\nYour goal for this assignment is to get up and running with the cancensus package. You can learn more about the cancensus package here: https://mountainmath.github.io/cancensus/index.html\nTo submit for this assignment: a reproducible RMarkdown file that develops an analysis of census data for a geographical location in Canada of interest to you. You are free to incorporate external data from other sources if you wish, but the focus should be on data that are in the census. The geography of interest must meet the following criteria:\n\nhas a name that starts with same letter as your first name or last name;\nis comprised of at least 30 geographic units; and\nis somewhere that you have not personally visited.\n\nThe analysis may focus on traditional census themes like population change or dive deep into more specific demographic or regional questions. Your analysis should present a coherent data story, and should mix visualizations and written interpretations of your analysis. You must include all R code for reproducing your report, however do not have to show all of the code in the output in the final report (i.e. you can have echo=FALSE in some of your code chunks if you want them hidden from the output - learn how to use chunk options in RStudio https://rmarkdown.rstudio.com/lesson-3.html ). Focus on quality over quantity, only include analysis which contributes to your overall narrative, do not include every type of graph or model you explored.\nMarks will be reserved for detailed comment on how lessons from Wilke’s Fundamentals of Data Visualization were applied to each figure."
  },
  {
    "objectID": "assignments.html#analytics-demo",
    "href": "assignments.html#analytics-demo",
    "title": "4  Assignments",
    "section": "4.3 Analytics Demo",
    "text": "4.3 Analytics Demo\nStudents will work on a major project which will require a technical overview of an analysis of their choosing. None of the data used in this analysis can come from the student’s own research group. This will be presented in the last weeks of the course as a technical demonstration in class.\nThe goal of this project is to demonstrate a technical topic to an audience in an interesting way. Being able to communicate technical details in accessible ways is a critical skill for working with collaborators on scientific projects. People need to know what you did, what decisions were made and why, how they affected the outcome, and potential issues or shortcomings in the approach taken. While peer-review is one part of the scientific knowledge production process - increasingly it is not sufficient to just describe your methods in a paper, but these must be presented as supplementary code or a notebook which documents exact data processing steps.\nYour task for the term project is to provide a complete analytic walk-through of an existing analysis from a paper in an area of interest (i.e., replicated by you but not from your research group) or through a demonstration of a specialized statistical or analysis method through the use of R packages. If you are demoing a method this must be a completely new demonstration and ideally will compare and contrast multiple packages, not simply a rehashing of an existing tutorial or vignette. Please consult with me to confirm your chosen topic.\n\nDemonstration: In this part of the project your goal is to articulate as clearly as possible to a scientific but non-specialized audience the full scope of your analysis. This should comprise about half of your written report and about 70% of your presentation/overview in class.\nCritique: In this part of the project you should critically analyze the analysis and/or methods implemented in the package. Focus here on issues of data quality, uncertainty, key parameters, workflow, etc. Your aim here is to provide a critical overview of the methods and analysis presented so as to provide guidance and advice to scientific collaborators.\nSubmission: The term project here is comprised of a written report and an in-class demonstration. The report will be worth 65 points according to the following breakdown:\nTechnical depth ‒ /40\nCritique ‒ /25\nAccuracy ‒ /20\nWriting style ‒ /15\nThe presentation will be worth 35 points and graded according to the following breakdown:\nAesthetic appeal ‒ /25\nClarity and communication style ‒ /25\nTechnical completeness ‒ /50\n\nThe report should be no longer than 4000 words. The presentation should be between 13-15 minutes. The presentation file will not be submitted for grading."
  },
  {
    "objectID": "assignments.html#participation",
    "href": "assignments.html#participation",
    "title": "4  Assignments",
    "section": "4.4 Participation",
    "text": "4.4 Participation\nStudents will be expected to attend and participate in designated course times. Participate includes contributing to discussions, presenting small pieces of weekly homework, and working collaboratively with other students when needed."
  },
  {
    "objectID": "assignments.html#course-notebook",
    "href": "assignments.html#course-notebook",
    "title": "4  Assignments",
    "section": "4.5 Course Notebook",
    "text": "4.5 Course Notebook\nStudents will keep a notebook to keep track of their learning throughout the course. These can be as digital or hardcopy, and will be graded at the end of the course for depth and quality of notes, and coverage of topics covered in the course. Hardcopy notebooks will be returned to students after grading."
  },
  {
    "objectID": "assignments.html#assignment-1---importing-parsing-and-querying-data-in-the-wild",
    "href": "assignments.html#assignment-1---importing-parsing-and-querying-data-in-the-wild",
    "title": "4  Assignments",
    "section": "4.1 Assignment 1 - Importing, parsing, and querying data in the wild",
    "text": "4.1 Assignment 1 - Importing, parsing, and querying data in the wild\nThe National Earthquake Information Center (NEIC) determines the location and size of all significant earthquakes that occur worldwide and disseminates this information immediately to national and international agencies, scientists, critical facilities, and the general public. The NEIC compiles and provides to scientists and to the public an extensive seismic database that serves as a foundation for scientific research through the operation of modern digital national and global seismograph networks and cooperative international agreements. The NEIC is the national data center and archive for earthquake information.\nThis dataset includes a record of the date, time, location, depth, magnitude, and source of every earthquake with a reported magnitude 5.5 or higher since 1965.\nYou can use this Rmd file as a template. Rstudio (now posit) has some easy to follow lessons on RMarkdown https://rmarkdown.rstudio.com/lesson-1.html . We will briefly discuss Rmarkdown in class.\nYour assignment should answer the following questions and be as reproducible as you can make it (i.e., I should be able to reproduce your answers).This means that you must read data in from a URL so that I can replicate your work, do not include any external data files in your submission, only submit one .Rmd file. You can use external data to supplement your anlayses if you want to. For each answer provide a short write up explaining the approach you took to the question. There are not necessarily correct answers, and I expect your answers to vary from classmates, however you should be able to provide a clear illustration via your code of how you arrived at the conclusion you did.\nQuestions:\n\nRead the data in and clean it for analysis, using the readr package functions for reading and parsing data. [5 marks]\nDid more earthquakes happen on weekends or weekdays? Include a figure [5 marks]\nHas there been any change in the frequency of earthquakes? Include a figure [5 marks]\nWhere were there more earthquakes in the 1980s, South America or North America? Include a figure [5 marks]\nHas there been any geographic shifts in the distribution of earthquakes? [10 marks] Include a figure\nComment on how lessons from Wilke’s Fundamentals of Data Visualization were applied to each figure with specific reference to book sections [5 marks]"
  },
  {
    "objectID": "assignments.html#assignment-2---real-world-data-wrangling",
    "href": "assignments.html#assignment-2---real-world-data-wrangling",
    "title": "4  Assignments",
    "section": "4.2 Assignment 2 - Real world data wrangling",
    "text": "4.2 Assignment 2 - Real world data wrangling\nThe Canadian Census from 2021 will soon be released and made available to the public. You will analyze Canadian census data for this assignment. However, the real goal of this assignment is to get you familiar with the process of learning a new R package. More than anything - the R landscape of packages is quickly changing and being able to learn about, understand, and use new packages is a vital skill for scientific data wrangling. Often, new published papers will have related R packages and may or may not have clear documentation or vignettes (which are best for getting up and running). Evaluating an R package requires quickly ascertaining whether a package can do what you need it to, how to format data for it, what outputs are generated, and what parameters need to be set/configured. There is very little standardization across R packages (outside of the tidyverse) so this step of evaluation can take some time.\nYour goal for this assignment is to get up and running with the cancensus package. You can learn more about the cancensus package here: https://mountainmath.github.io/cancensus/index.html\nTo submit for this assignment: a reproducible RMarkdown file that develops an analysis of census data for a geographical location in Canada of interest to you. You are free to incorporate external data from other sources if you wish, but the focus should be on data that are in the census. The geography of interest must meet the following criteria:\n\nhas a name that starts with same letter as your first name or last name;\nis comprised of at least 30 geographic units; and\nis somewhere that you have not personally visited.\n\nThe analysis may focus on traditional census themes like population change or dive deep into more specific demographic or regional questions. Your analysis should present a coherent data story, and should mix visualizations and written interpretations of your analysis. You must include all R code for reproducing your report, however do not have to show all of the code in the output in the final report (i.e. you can have echo=FALSE in some of your code chunks if you want them hidden from the output - learn how to use chunk options in RStudio https://rmarkdown.rstudio.com/lesson-3.html ). Focus on quality over quantity, only include analysis which contributes to your overall narrative, do not include every type of graph or model you explored.\nMarks will be reserved for detailed comment on how lessons from Wilke’s Fundamentals of Data Visualization were applied to each figure."
  },
  {
    "objectID": "practice.html#pipes-and-functions",
    "href": "practice.html#pipes-and-functions",
    "title": "3  Data Wrangling in Practice",
    "section": "3.1 Pipes and functions",
    "text": "3.1 Pipes and functions\n\n3.1.1 Reading this week\nR4Ds Chapters 17, 18, 19"
  },
  {
    "objectID": "practice.html#functions",
    "href": "practice.html#functions",
    "title": "3  Data Wrangling in Practice",
    "section": "3.2 Functions",
    "text": "3.2 Functions\n\n3.2.1 Reading this week\nR4Ds Chapter 19 Functions"
  },
  {
    "objectID": "practice.html#functions-more-functions-and-packages",
    "href": "practice.html#functions-more-functions-and-packages",
    "title": "3  Data Wrangling in Practice",
    "section": "3.3 Functions, more functions and packages",
    "text": "3.3 Functions, more functions and packages\n\n3.3.1 Reading this week\nHart EM, Barmby P, LeBauer D, Michonneau F, Mount S, Mulrooney P, et al. 2016. Ten Simple Rules for Digital Data Storage. PLoS Comput Biol12(10): e1005097, DOI: 10.1371/journal.pcbi.1005097"
  },
  {
    "objectID": "wrangling.html#intro-data-vis",
    "href": "wrangling.html#intro-data-vis",
    "title": "2  Wrangling",
    "section": "2.1 Intro, Data vis",
    "text": "2.1 Intro, Data vis\nThis week will provide an introduction to data science using R. You will be introduced to data science through the lens of exploratory data analysis, beginning with the Explore section of the R4DS textbook, read and work through the following chapters:\n\n2.1.1 Reading this week\n\nR4DS Chapter 2 Introduction\nR4DS Chapter 4 Dta vis\nR4DS Chapter 3 Workflow basics\npalmerpenguins package homework"
  },
  {
    "objectID": "wrangling.html#data-workflows",
    "href": "wrangling.html#data-workflows",
    "title": "2  Wrangling",
    "section": "2.2 Data workflows",
    "text": "2.2 Data workflows\nThis week will cover the surprisingly important topic of data workflows including input and output. In the Wrangle section of the textbook, read and work through the following chapters:\n\n2.2.1 Reading this week\n\nR4DS Chapter 6 Workflow scripts\nR4DS Chapter 8 Workflow projects\nWickham. 2014. Tidy Data. Journal of Statistical Software, 59(10), 1–23. DOI: 10.18637/jss.v059.i10\nhere package homework\nJenny Bryan’s view on project-oriented workflows"
  },
  {
    "objectID": "wrangling.html#data-transformations-and-wrangling",
    "href": "wrangling.html#data-transformations-and-wrangling",
    "title": "2  Wrangling",
    "section": "2.3 Data transformations and wrangling",
    "text": "2.3 Data transformations and wrangling\nThis week will cover changing, creating, reordering variables in order to wrangle and organise data. Ideas of wider data vs longer data (and messy) are important here too.\n\n2.3.1 Reading this week\n\nR4DS Chapter 5 Data transformation\nR4DS Chapter 9, 10, 11, 12\nKarl W. Broman & Kara H. Woo (2018) Data Organization in Spreadsheets, The American Statistician, 72:1, 2-10, DOI: 10.1080/00031305.2017.1375989"
  },
  {
    "objectID": "wrangling.html#exploration-data-types",
    "href": "wrangling.html#exploration-data-types",
    "title": "2  Wrangling",
    "section": "2.4 Exploration, data types",
    "text": "2.4 Exploration, data types\nThis will continue to cover more wrangling and dealing with varying data types.\n\n2.4.1 Reading this week\n\nR4DS Chapter 9, 10, 11, 12 continued\nAmelia McNamara & Nicholas J. Horton (2018) Wrangling Categorical Data in R, The American Statistician, 72:1, 97-104, DOI: 10.1080/00031305.2017.1356375\nWHO example in R4DS Chapter 12"
  },
  {
    "objectID": "wrangling.html#tidying-data-data-forms-and-formats",
    "href": "wrangling.html#tidying-data-data-forms-and-formats",
    "title": "2  Wrangling",
    "section": "2.5 Tidying data, data forms and formats",
    "text": "2.5 Tidying data, data forms and formats\nThis week will move from wrangling data to using and creating relational data, dealing with and using strings and rexexps, and ideas around categorical (aka factors) variables.\n\n2.5.1 Reading this week\n\nR4DS Chapter 13 Relational data\nR4DS Chapter 14 Strings\nR4DS Chapter 15 Factors\nAmelia McNamara & Nicholas J. Horton (2018) Wrangling Categorical Data in R, The American Statistician, 72:1, 97-104, DOI: 10.1080/00031305.2017.1356375"
  },
  {
    "objectID": "wrangling.html#dates-times-time-series",
    "href": "wrangling.html#dates-times-time-series",
    "title": "2  Wrangling",
    "section": "2.6 Dates, times, time series",
    "text": "2.6 Dates, times, time series\nThis week will cover everyone’s favourites dates and times. Time series data are a special type of data where we may have to consider the temporal autocorrelation as well as the common push to produce forecasts and fables.\n\n2.6.1 Reading this week\n\nR4DS Chapter 15 Factors\nR4DS Chapter 16 Dates and times"
  }
]